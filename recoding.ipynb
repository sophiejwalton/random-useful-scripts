{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import numpy as np\n",
    "import Bio\n",
    "import scipy.spatial\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rnai_scripts import *\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "\n",
    "# Enable viewing Bokeh plots in the notebook\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf_vals(data):\n",
    "    \"\"\"Return x and y values for an ECDF.\"\"\"\n",
    "    return np.sort(data), np.arange(1, len(data)+1) / len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAi recoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Smed transcriptome\n",
    "We read in the Smed_v6 transcriptome orfs that were extracted using orfipy. We then join them all into one string and obtain the codon frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/dd_Smed_v6_transcripts_orfs_large3.fa' # makes smallest proteins be around 30 amino acids\n",
    "descriptors, seqs = read_many_fasta(fname)\n",
    "# join all ORFS into one large transcriptome \n",
    "transcriptome = ''.join(seqs)\n",
    "# get aminoacidweights and codon weights \n",
    "\n",
    "codon_frequencies_dic = get_codon_frequencies(transcriptome) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get frequencies of doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubletscode = get_codon_frequencies_doublets(transcriptome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also found a published version of amino acid frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/codon_usage_smed.csv')\n",
    "\n",
    "\n",
    "AAs = df['codon'].values\n",
    "freqs = df['frequency'].values/1000.\n",
    "\n",
    "codon_frequencies_dic_published = {}\n",
    "for i in range(len(AAs)):\n",
    "    codon_frequencies_dic_published[AAs[i]] = freqs[i]\n",
    "print(sum(freqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average discrepency between the doublets vs. codon frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_published_vs_me = {}\n",
    "for a in AAs:\n",
    "    \n",
    "    diff_published_vs_me[a] = codon_frequencies_dic_published[a] - codon_frequencies_dic[a]\n",
    "values = np.array(list(diff_published_vs_me.values()))\n",
    "print(np.mean(values))\n",
    "print(np.mean(np.abs(values))) # values usually on order \n",
    "print(np.sum(np.abs(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find the discrepencies between the frequencies of each doublet vs. the product frequency of the separate codons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff_dic = {}\n",
    "diff_dic_norm = {}\n",
    "for pair in doubletscode.keys():\n",
    "    if 'TAA' == pair[:3]:\n",
    "        continue\n",
    "    if 'TAG' == pair[:3]:\n",
    "        continue\n",
    "    if 'TGA' == pair[:3]:\n",
    "        continue\n",
    "    \n",
    "    freq1 = codon_frequencies_dic[pair[:3]]\n",
    "    freq2 = codon_frequencies_dic[pair[3:]]\n",
    "    \n",
    "    diff_dic_norm[pair] = (doubletscode[pair] - freq1*freq2)/np.max(np.array([freq1, freq2]))\n",
    "    diff_dic[pair] = (doubletscode[pair] - freq1*freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "p = bokeh.plotting.figure(\n",
    "    frame_width=400,\n",
    "    frame_height=300,\n",
    "    x_axis_label='diff',\n",
    "    y_axis_label='Dist',\n",
    "  #  x_axis_type = 'log'\n",
    "    \n",
    ")\n",
    "diffs, ecdf_diffs = ecdf_vals(np.array(list(diff_dic.values())))\n",
    "print(np.sum(np.array(list(doubletscode.values()))))\n",
    "p.circle(diffs*1e4, ecdf_diffs)\n",
    "\n",
    "#diffs, ecdf_diffs = ecdf_vals(np.array(list(doublets.values())))\n",
    "#p.circle(diffs, ecdf_diffs, color = 'orange')\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "p = bokeh.plotting.figure(\n",
    "    frame_width=400,\n",
    "    frame_height=300,\n",
    "    x_axis_label='diff',\n",
    "    y_axis_label='Dist',\n",
    "  #  x_axis_type = 'log'\n",
    "    \n",
    ")\n",
    "diffs, ecdf_diffs = ecdf_vals(np.array(list(diff_dic_norm.values())))\n",
    "print(np.sum(np.array(list(doubletscode.values()))))\n",
    "p.circle(diffs, ecdf_diffs)\n",
    "\n",
    "#diffs, ecdf_diffs = ecdf_vals(np.array(list(doublets.values())))\n",
    "#p.circle(diffs, ecdf_diffs, color = 'orange')\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(list(diff_dic_norm.values()))\n",
    "inds_sort = np.argsort(values)\n",
    "keys = np.array(list(diff_dic_norm.keys()))\n",
    "keys[inds_sort][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(list(diff_dic.values()))*1e4\n",
    "inds_sort = np.argsort(values)\n",
    "keys = np.array(list(diff_dic.keys()))\n",
    "keys[inds_sort][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dic['AAAAAA']*1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubletscode['AAAAAA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_frequencies_dic['AAA']*codon_frequencies_dic['AAA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our codon frequencies dictionary to compute CAI weights (based on the weight definition for the CAI) for all codons \n",
    "\n",
    "$$w_i = \\frac{f_i}{\\max (f_j)} i,j \\in [ \\text{synonymouse codons for amino acid} ]$$\n",
    "\n",
    "Where $f_i$ is the frequency of codon $i$. \n",
    "\n",
    "We obtain two dictionaries: \n",
    "\n",
    "\n",
    "aminoacidweights: keys are amino acids, values are arrays of $w_i$ for all synonymous codons. The order of the codons is the as those used in aminoacidcode. \n",
    "    \n",
    "gencodeweights: keys are codons, values are $w_i$ for each codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminoacidweights, gencodeweights = get_codon_weights(codon_frequencies_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pickle dump everything so we do not have to repeat the above line later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( aminoacidweights,\n",
    "            open( \"data/Smed_transcriptome_aminoacidweights.p\", \"wb\" ) )\n",
    "pickle.dump( gencodeweights, \n",
    "            open( \"data/Smed_transcriptome_gencodeweights.p\", \"wb\" ) )\n",
    "pickle.dump( aminoacidcode,\n",
    "            open( \"data/aminoacidcode.p\", \"wb\" ))\n",
    "pickle.dump( doubletscode,\n",
    "            open( \"data/doubletscode.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reload everything with pickle because why not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminoacidweights = pickle.load( open( \"data/Smed_transcriptome_aminoacidweights.p\",\n",
    "                                     \"rb\" ) )\n",
    "gencodeweights = pickle.load( open( \"data/Smed_transcriptome_gencodeweights.p\", \n",
    "                                   \"rb\" ) )\n",
    "aminoacidcode = pickle.load(open(\"data/aminoacidcode.p\", 'rb'))\n",
    "doubletscode = pickle.load(\n",
    "            open( \"data/doubletscode.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We recode the luc ORFS!!!! \n",
    "\n",
    "Since SmedNluc2 is so short we must RNAi the whole thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SmedNluc2_ORF = 'ATGGTGTTTACTTTGGAAGATTTTGTTGGAGATTGGAGACAAACTGCTGGTTACAATCTGGATCAGGTACTGGAACAAGGCGGTGTTAGTTCATTATTCCAAAACCTGGGTGTGAGTGTAACTCCGATTCAGCGAATAGTGTTGTCTGGAGAAAATGGGCTGAAGATTGATATACACGTCATAATTCCATACGAAGGCTTAAGCGGTGATCAAATGGGACAAATTGAAAAAATTTTTAAAGTAGTTTACCCAGTTGACGACCATCATTTTAAAGTTATCCTTCATTACGGTACACTGGTTATAGATGGTGTAACTCCAAATATGATCGATTATTTCGGAAGACCTTACGAAGGCATAGCCGTTTTTGATGGAAAAAAGATTACAGTAACAGGTACATTGTGGAACGGAAATAAGATTATTGACGAACGTTTAATTAACCCAGATGGAAGTTTGCTCTTTAGAGTTACAATTAATGGTGTGACAGGATGGAGATTATGCGAACGGATACTCGCGTAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SmedNluc2_protein = 'MVFTLEDFVGDWRQTAGYNLDQVLEQGGVSSLFQNLGVSVTPIQRIVLSGENGLKIDIHVIIPYEGLSGDQMGQIEKIFKVVYPVDDHHFKVILHYGTLVIDGVTPNMIDYFGRPYEGIAVFDGKKITVTGTLWNGNKIIDERLINPDGSLLFRVTINGVTGWRLCERILA*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hluc_ORF = 'ATGGTCTTCACACTCGAAGATTTCGTTGGGGACTGGCGACAGACAGCCGGCTACAACCTGGACCAAGTCCTTGAACAGGGAGGTGTGTCCAGTTTGTTTCAGAATCTCGGGGTGTCCGTAACTCCGATCCAAAGGATTGTCCTGAGCGGTGAAAATGGGCTGAAGATCGACATCCATGTCATCATCCCGTATGAAGGTCTGAGCGGCGACCAAATGGGCCAGATCGAAAAAATTTTTAAGGTGGTGTACCCTGTGGATGATCATCACTTTAAGGTGATCCTGCACTATGGCACACTGGTAATCGACGGGGTTACGCCGAACATGATCGACTATTTCGGACGGCCGTATGAAGGCATCGCCGTGTTCGACGGCAAAAAGATCACTGTAACAGGGACCCTGTGGAACGGCAACAAAATTATCGACGAGCGCCTGATCAACCCCGACGGCTCCCTGCTGTTCCGAGTAACCATCAACGGAGTGACCGGCTGGCGGCTGTGCGAACGCATTCTGGCGTAA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder what the CAI for each ORF is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CAI for SMed Nuc:', get_CAI(SmedNluc2_ORF, gencodeweights))\n",
    "print('CAI for Human Nuc:', get_CAI(Hluc_ORF, gencodeweights))\n",
    "print('Hamming Distance vs Smed vs Human Nuc', get_hamming_dist(SmedNluc2_ORF, Hluc_ORF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function get_RNAi_seq to randomly sample different recoded Luc proteins. \n",
    "\n",
    "The function get_RNAi_seq requires the ORF, protein sequence, an aminoacidweights and gencodeweights dictionary. We run 1000 random samples and do not enforce that every codon be different. It returns the list of tested sequences (seqs), scores ($CAI + D$/2) for each sequence, codon adaptation indices (CAIs), and Hamming distances (dists = $D$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doublest_likelihood(dna_seq, weights_dic):\n",
    "    '''\n",
    "    Obtains Codon Adaptation Index (CAI) for a given DNA_seq calculated using weights_dic\n",
    "    CAI = (w_1*.w_i*..w_N)^(1/N) where w_i is the weight of codon i. \n",
    "    \n",
    "    Inputs:\n",
    "        dna_seq: ORF in form of string to evaluate CAI\n",
    "        weights_dic: dictionary of CAI weights for each codon. Values are weights and keys are codons. \n",
    "    '''\n",
    "    if len(dna_seq) % 3 > 0.:\n",
    "        raise ValueError(\"Length of DNA sequence must be divisble by 3\")\n",
    "    ncodons = int(len(dna_seq)//3)\n",
    "    score = 0. \n",
    "    for i in range(ncodons-1):\n",
    "        start = i*3\n",
    "        end = start + 6\n",
    "        codonpair = dna_seq[start:end].upper()\n",
    "        score = score+ np.log(weights_dic[codonpair])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, scores, cais, dists = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1000,  enforce_different_codons = False, random = True)\n",
    "\n",
    "\n",
    "best_seq, best_score, best_cai, best_dist = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1,  enforce_different_codons = False, random = False)\n",
    "\n",
    "best_doublet = get_doublest_likelihood(best_seq[0], doubletscode)\n",
    "doublets_scores = np.array([get_doublest_likelihood(seq, doubletscode) for seq in seqs])\n",
    "print(best_cai, best_dist, best_doublet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We redo the process but enforce that every codon must be different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_diff, scores_diff, cais_diff, dists_diff = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1000,  enforce_different_codons = True, random = True)\n",
    "\n",
    "best_seq_diff, best_score_diff, best_cai_diff, best_dist_diff = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1,  enforce_different_codons = True, random = False)\n",
    "best_doublet_diff = get_doublest_likelihood(best_seq_diff[0], doubletscode)\n",
    "doublets_scores_diff = np.array([get_doublest_likelihood(seq, doubletscode) for seq in seqs_diff])\n",
    "print(best_cai_diff, best_dist_diff, best_doublet_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the best sequences of our random simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(cais_diff), np.max(dists_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat with wiggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_diff, scores_diff, cais_wiggle, dists_wiggle = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights,\n",
    "                            gencodeweights, trials = 1000,  enforce_different_codons = True, random = True, wiggle = True,)\n",
    "\n",
    "best_seq_diff, best_score_diff, best_cai_diff_wiggle, best_dist_diff_wiggle = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1,  enforce_different_codons = True, random = False,  wiggle = True\n",
    "                                                                            )\n",
    "best_doublet_diff_wiggle = get_doublest_likelihood(best_seq_diff[0], doubletscode)\n",
    "doublets_scores_wiggle = np.array([get_doublest_likelihood(seq, doubletscode) for seq in seqs_diff])\n",
    "print(best_cai_diff_wiggle, best_dist_diff_wiggle, best_doublet_diff_wiggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(cais_wiggle), np.max(dists_wiggle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doublets baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_doub, scores_doub, cais_doub, dists_doub = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1000,  enforce_different_codons =True, random = True,\n",
    "                                                            pairs = True, doubletscode = doubletscode)\n",
    "\n",
    "best_seq_doub, best_score_doub, best_cai_doub, best_dist_doub = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1,  enforce_different_codons = True, random = False,\n",
    "                                                                            pairs = True, doubletscode = doubletscode,)\n",
    "best_doublet_doub = get_doublest_likelihood(best_seq_doub[0], doubletscode)\n",
    "doublets_scores_doub= np.array([get_doublest_likelihood(seq, doubletscode) for seq in seqs_doub])\n",
    "print(best_cai_doub, best_dist_doub, best_doublet_doub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_doub, scores_doub, cais_doub_wigg, dists_doub_wigg = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1000,  enforce_different_codons =True, random = True, wiggle = True,\n",
    "                                                            pairs = True, doubletscode = doubletscode)\n",
    "\n",
    "best_seq_doub, best_score_doub, best_cai_doub_wiggle, best_dist_doub_wiggle = get_RNAi_seq(SmedNluc2_ORF, SmedNluc2_protein, aminoacidweights, \n",
    "                            gencodeweights, trials = 1,  enforce_different_codons = True, random = False, wiggle = True,\n",
    "                                                                            pairs = True, doubletscode = doubletscode,)\n",
    "best_doublet_doub = get_doublest_likelihood(best_seq_doub[0], doubletscode)\n",
    "doublets_scores_doub_wigg = np.array([get_doublest_likelihood(seq, doubletscode) for seq in seqs_doub])\n",
    "print(best_cai_doub_wiggle, best_dist_doub_wiggle, best_doublet_doub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to compute ECDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot ECDFs of the CAIs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "p = bokeh.plotting.figure(\n",
    "    frame_width=400,\n",
    "    frame_height=300,\n",
    "    x_axis_label='CAI',\n",
    "    y_axis_label='ECDF',\n",
    "    \n",
    ")\n",
    "cais, ecdf_cais = ecdf_vals(cais)\n",
    "p.circle(cais, ecdf_cais, legend_label = 'Not all different ')\n",
    "\n",
    "cais_diff, ecdf_cais_diff = ecdf_vals(cais_diff)\n",
    "p.circle(cais_diff, ecdf_cais_diff, legend_label = 'all different', color = 'orange')\n",
    "\n",
    "cais_wiggle, ecdf_cais_wiggle = ecdf_vals(cais_wiggle)\n",
    "p.circle(cais_wiggle, ecdf_cais_wiggle, legend_label = 'all different wiggle', color = 'green')\n",
    "\n",
    "cais_doub, ecdf_cais_doub = ecdf_vals(cais_doub)\n",
    "p.circle(cais_doub, ecdf_cais_doub, legend_label = 'doublets', color = 'red')\n",
    "\n",
    "cais_doub_wiggle, ecdf_cais_doub_wiggle = ecdf_vals(cais_doub_wigg)\n",
    "p.circle(cais_doub_wiggle, ecdf_cais_doub_wiggle,\n",
    "         legend_label = 'doublets wig', color = 'pink')\n",
    "\n",
    "\n",
    "p.legend.location = 'bottom_right'\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot ECDFs of the hamming distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "p = bokeh.plotting.figure(\n",
    "    frame_width=400,\n",
    "    frame_height=300,\n",
    "    x_axis_label='Hamming Distance',\n",
    "    y_axis_label='ECDF',\n",
    "    \n",
    ")\n",
    "dists, ecdf_dists = ecdf_vals(dists)\n",
    "p.circle(dists, ecdf_dists, legend_label = 'Not all different ')\n",
    "\n",
    "dists_diff, ecdf_dists_diff = ecdf_vals(dists_diff)\n",
    "p.circle(dists_diff, ecdf_dists_diff, legend_label = 'all different', color = 'orange')\n",
    "\n",
    "\n",
    "dists_diff_wiggle, ecdf_dists_diff_wiggle = ecdf_vals(dists_wiggle)\n",
    "p.circle(dists_diff_wiggle, ecdf_dists_diff_wiggle, legend_label = 'wiggle', color = 'green')\n",
    "\n",
    "dists_doub, ecdf_dists_doub = ecdf_vals(dists_doub)\n",
    "p.circle(dists_doub, ecdf_dists_doub, legend_label = 'doublets', color = 'red')\n",
    "\n",
    "dists_doub_wiggle, ecdf_dists_doub_wiggle = ecdf_vals(dists_doub_wigg)\n",
    "p.circle(dists_doub_wiggle, ecdf_dists_doub_wiggle,\n",
    "         legend_label = 'doublets wig', color = 'pink')\n",
    "\n",
    "\n",
    "p.legend.location = 'bottom_right'\n",
    "p.x_range = bokeh.models.Range1d(.1, .6)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "p = bokeh.plotting.figure(\n",
    "    frame_width=400,\n",
    "    frame_height=300,\n",
    "    x_axis_label='Hamming Distance',\n",
    "    y_axis_label='ECDF',\n",
    "    \n",
    ")\n",
    "dists, ecdf_dists = ecdf_vals(doublets_scores)\n",
    "p.circle(dists, ecdf_dists, legend_label = 'Not all different ')\n",
    "\n",
    "dists_diff, ecdf_dists_diff = ecdf_vals(doublets_scores_diff)\n",
    "p.circle(dists_diff, ecdf_dists_diff, legend_label = 'all different', color = 'orange')\n",
    "\n",
    "\n",
    "dists_diff_wiggle, ecdf_dists_diff_wiggle = ecdf_vals(doublets_scores_wiggle)\n",
    "p.circle(dists_diff_wiggle, ecdf_dists_diff_wiggle, legend_label = 'wiggle', color = 'green')\n",
    "\n",
    "dists_doub, ecdf_dists_doub = ecdf_vals(doublets_scores_doub)\n",
    "p.circle(dists_doub, ecdf_dists_doub, legend_label = 'doublets', color = 'red')\n",
    "\n",
    "dists_doub_wiggle, ecdf_dists_doub_wiggle = ecdf_vals(doublets_scores_doub_wigg)\n",
    "p.circle(dists_doub_wiggle, ecdf_dists_doub_wiggle,\n",
    "         legend_label = 'doublets wig', color = 'pink')\n",
    "\n",
    "\n",
    "p.legend.location = 'bottom_right'\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
